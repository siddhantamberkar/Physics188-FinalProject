{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cc3d7c-152f-46f0-8fab-78a0790b3963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6921143_H S15 EO.set...\n",
      "Saved 302 segments for 6921143_H S15 EO.set\n",
      "Processing 6921959_H S15 EO.set...\n",
      "Saved 302 segments for 6921959_H S15 EO.set\n",
      "Processing H S1 EC.set...\n",
      "Saved 300 segments for H S1 EC.set\n",
      "Processing H S1 EO.set...\n",
      "Saved 351 segments for H S1 EO.set\n",
      "Processing H S10 EC.set...\n",
      "Saved 376 segments for H S10 EC.set\n",
      "Processing H S10 EO.set...\n",
      "Saved 300 segments for H S10 EO.set\n",
      "Processing H S11 EC.set...\n",
      "Saved 300 segments for H S11 EC.set\n",
      "Processing H S11 EO.set...\n",
      "Saved 302 segments for H S11 EO.set\n",
      "Processing H S12 EO.set...\n",
      "Saved 300 segments for H S12 EO.set\n",
      "Processing H S13 EC.set...\n",
      "Saved 300 segments for H S13 EC.set\n",
      "Processing H S13 EO.set...\n",
      "Saved 303 segments for H S13 EO.set\n",
      "Processing H S14 EC.set...\n",
      "Saved 302 segments for H S14 EC.set\n",
      "Processing H S14 EO.set...\n",
      "Saved 194 segments for H S14 EO.set\n",
      "Processing H S15 EC.set...\n",
      "Saved 300 segments for H S15 EC.set\n",
      "Processing H S16 EC.set...\n",
      "Saved 292 segments for H S16 EC.set\n",
      "Processing H S16 EO.set...\n",
      "Saved 299 segments for H S16 EO.set\n",
      "Processing H S17 EC.set...\n",
      "Saved 309 segments for H S17 EC.set\n",
      "Processing H S17 EO.set...\n",
      "Saved 301 segments for H S17 EO.set\n",
      "Processing H S18 EO.set...\n",
      "Saved 301 segments for H S18 EO.set\n",
      "Processing H S19 EC.set...\n",
      "Saved 300 segments for H S19 EC.set\n",
      "Processing H S19 EO.set...\n",
      "Saved 301 segments for H S19 EO.set\n",
      "Processing H S2 EC.set...\n",
      "Saved 302 segments for H S2 EC.set\n",
      "Processing H S2 EO.set...\n",
      "Saved 302 segments for H S2 EO.set\n",
      "Processing H S20 EC.set...\n",
      "Saved 307 segments for H S20 EC.set\n",
      "Processing H S20 EO.set...\n",
      "Saved 320 segments for H S20 EO.set\n",
      "Processing H S21 EC.set...\n",
      "Saved 301 segments for H S21 EC.set\n",
      "Processing H S21 EO.set...\n",
      "Saved 305 segments for H S21 EO.set\n",
      "Processing H S22 EC.set...\n",
      "Saved 301 segments for H S22 EC.set\n",
      "Processing H S22 EO.set...\n",
      "Saved 299 segments for H S22 EO.set\n",
      "Processing H S23 EC.set...\n",
      "Saved 302 segments for H S23 EC.set\n",
      "Processing H S23 EO.set...\n",
      "Saved 302 segments for H S23 EO.set\n",
      "Processing H S24 EC.set...\n",
      "Saved 299 segments for H S24 EC.set\n",
      "Processing H S24 EO.set...\n",
      "Saved 297 segments for H S24 EO.set\n",
      "Processing H S25 EC.set...\n",
      "Saved 301 segments for H S25 EC.set\n",
      "Processing H S26 EC.set...\n",
      "Saved 302 segments for H S26 EC.set\n",
      "Processing H S26 EO.set...\n",
      "Saved 305 segments for H S26 EO.set\n",
      "Processing H S27 EC.set...\n",
      "Saved 300 segments for H S27 EC.set\n",
      "Processing H S27 EO.set...\n",
      "Saved 300 segments for H S27 EO.set\n",
      "Processing H S28 EC.set...\n",
      "Saved 301 segments for H S28 EC.set\n",
      "Processing H S28 EO.set...\n",
      "Saved 299 segments for H S28 EO.set\n",
      "Processing H S29 EC.set...\n",
      "Saved 303 segments for H S29 EC.set\n",
      "Processing H S29 EO.set...\n",
      "Saved 301 segments for H S29 EO.set\n",
      "Processing H S3 EC.set...\n",
      "Saved 301 segments for H S3 EC.set\n",
      "Processing H S3 EO.set...\n",
      "Saved 305 segments for H S3 EO.set\n",
      "Processing H S30 EC.set...\n",
      "Saved 300 segments for H S30 EC.set\n",
      "Processing H S30 EO.set...\n",
      "Saved 300 segments for H S30 EO.set\n",
      "Processing H S4 EC.set...\n",
      "Saved 301 segments for H S4 EC.set\n",
      "Processing H S4 EO.set...\n",
      "Saved 295 segments for H S4 EO.set\n",
      "Processing H S5 EC.set...\n",
      "Saved 303 segments for H S5 EC.set\n",
      "Processing H S5 EO.set...\n",
      "Saved 312 segments for H S5 EO.set\n",
      "Processing H S6 EC.set...\n",
      "Saved 301 segments for H S6 EC.set\n",
      "Processing H S6 EO.set...\n",
      "Saved 303 segments for H S6 EO.set\n",
      "Processing H S7 EC.set...\n",
      "Saved 356 segments for H S7 EC.set\n",
      "Processing H S7 EO.set...\n",
      "Saved 303 segments for H S7 EO.set\n",
      "Processing H S8 EC.set...\n",
      "Saved 302 segments for H S8 EC.set\n",
      "Processing H S8 EO.set...\n",
      "Saved 302 segments for H S8 EO.set\n",
      "Processing H S9 EC.set...\n",
      "Saved 301 segments for H S9 EC.set\n",
      "Processing H S9 EO.set...\n",
      "Saved 302 segments for H S9 EO.set\n",
      "Processing MDD S1  EO.set...\n",
      "Saved 301 segments for MDD S1  EO.set\n",
      "Processing MDD S1 EC.set...\n",
      "Saved 303 segments for MDD S1 EC.set\n",
      "Processing MDD S10 EC.set...\n",
      "Saved 301 segments for MDD S10 EC.set\n",
      "Processing MDD S10 EO.set...\n",
      "Saved 300 segments for MDD S10 EO.set\n",
      "Processing MDD S11  EC.set...\n",
      "Saved 299 segments for MDD S11  EC.set\n",
      "Processing MDD S11 EO.set...\n",
      "Saved 299 segments for MDD S11 EO.set\n",
      "Processing MDD S12 EO.set...\n",
      "Saved 189 segments for MDD S12 EO.set\n",
      "Processing MDD S13 EC.set...\n",
      "Saved 300 segments for MDD S13 EC.set\n",
      "Processing MDD S13 EO.set...\n",
      "Saved 311 segments for MDD S13 EO.set\n",
      "Processing MDD S14 EC.set...\n",
      "Saved 300 segments for MDD S14 EC.set\n",
      "Processing MDD S14 EO.set...\n",
      "Saved 301 segments for MDD S14 EO.set\n",
      "Processing MDD S15 EC.set...\n",
      "Saved 300 segments for MDD S15 EC.set\n",
      "Processing MDD S15 EO.set...\n",
      "Saved 300 segments for MDD S15 EO.set\n",
      "Processing MDD S16 EO.set...\n",
      "Saved 298 segments for MDD S16 EO.set\n",
      "Processing MDD S17 EC.set...\n",
      "Saved 297 segments for MDD S17 EC.set\n",
      "Processing MDD S17 EO.set...\n",
      "Saved 299 segments for MDD S17 EO.set\n",
      "Processing MDD S18 EC.set...\n",
      "Saved 300 segments for MDD S18 EC.set\n",
      "Processing MDD S18 EO.set...\n",
      "Saved 302 segments for MDD S18 EO.set\n",
      "Processing MDD S19 EC.set...\n",
      "Saved 299 segments for MDD S19 EC.set\n",
      "Processing MDD S19 EO.set...\n",
      "Saved 298 segments for MDD S19 EO.set\n",
      "Processing MDD S2  EC.set...\n",
      "Saved 297 segments for MDD S2  EC.set\n",
      "Processing MDD S2 EO.set...\n",
      "Saved 297 segments for MDD S2 EO.set\n",
      "Processing MDD S20 EC.set...\n",
      "Saved 299 segments for MDD S20 EC.set\n",
      "Processing MDD S20 EO.set...\n",
      "Saved 302 segments for MDD S20 EO.set\n",
      "Processing MDD S21 EC.set...\n",
      "Saved 300 segments for MDD S21 EC.set\n",
      "Processing MDD S21 EO.set...\n",
      "Saved 300 segments for MDD S21 EO.set\n",
      "Processing MDD S22 EC.set...\n",
      "Saved 297 segments for MDD S22 EC.set\n",
      "Processing MDD S22 EO.set...\n",
      "Saved 297 segments for MDD S22 EO.set\n",
      "Processing MDD S23 EC.set...\n",
      "Saved 303 segments for MDD S23 EC.set\n",
      "Processing MDD S23 EO.set...\n",
      "Saved 307 segments for MDD S23 EO.set\n",
      "Processing MDD S24  EC.set...\n",
      "Saved 301 segments for MDD S24  EC.set\n",
      "Processing MDD S24 EO.set...\n",
      "Saved 300 segments for MDD S24 EO.set\n",
      "Processing MDD S25 EC.set...\n",
      "Saved 300 segments for MDD S25 EC.set\n",
      "Processing MDD S25 EO.set...\n",
      "Saved 300 segments for MDD S25 EO.set\n",
      "Processing MDD S26 EC.set...\n",
      "Saved 300 segments for MDD S26 EC.set\n",
      "Processing MDD S26 EO.set...\n",
      "Saved 300 segments for MDD S26 EO.set\n",
      "Processing MDD S27 EC.set...\n",
      "Saved 301 segments for MDD S27 EC.set\n",
      "Processing MDD S27 EO.set...\n",
      "Saved 299 segments for MDD S27 EO.set\n",
      "Processing MDD S28 EC.set...\n",
      "Saved 301 segments for MDD S28 EC.set\n",
      "Processing MDD S28 EO.set...\n",
      "Saved 302 segments for MDD S28 EO.set\n",
      "Processing MDD S29 EC.set...\n",
      "Saved 300 segments for MDD S29 EC.set\n",
      "Processing MDD S29 EO.set...\n",
      "Saved 300 segments for MDD S29 EO.set\n",
      "Processing MDD S3 EC.set...\n",
      "Saved 180 segments for MDD S3 EC.set\n",
      "Processing MDD S3 EO.set...\n",
      "Saved 301 segments for MDD S3 EO.set\n",
      "Processing MDD S30 EC.set...\n",
      "Saved 241 segments for MDD S30 EC.set\n",
      "Processing MDD S30 EO.set...\n",
      "Saved 300 segments for MDD S30 EO.set\n",
      "Processing MDD S31 EC.set...\n",
      "Saved 302 segments for MDD S31 EC.set\n",
      "Processing MDD S31 EO.set...\n",
      "Saved 301 segments for MDD S31 EO.set\n",
      "Processing MDD S32 EC.set...\n",
      "Saved 299 segments for MDD S32 EC.set\n",
      "Processing MDD S32 EO.set...\n",
      "Saved 300 segments for MDD S32 EO.set\n",
      "Processing MDD S33 EC.set...\n",
      "Saved 298 segments for MDD S33 EC.set\n",
      "Processing MDD S33 EO.set...\n",
      "Saved 296 segments for MDD S33 EO.set\n",
      "Processing MDD S34 EC.set...\n",
      "Saved 298 segments for MDD S34 EC.set\n",
      "Processing MDD S34 EO.set...\n",
      "Saved 296 segments for MDD S34 EO.set\n",
      "Processing MDD S4 EO.set...\n",
      "Saved 301 segments for MDD S4 EO.set\n",
      "Processing MDD S5 EC.set...\n",
      "Saved 302 segments for MDD S5 EC.set\n",
      "Processing MDD S5 EO.set...\n",
      "Saved 302 segments for MDD S5 EO.set\n",
      "Processing MDD S6 EC.set...\n",
      "Saved 302 segments for MDD S6 EC.set\n",
      "Processing MDD S6 EO.set...\n",
      "Saved 301 segments for MDD S6 EO.set\n",
      "Processing MDD S7  EC.set...\n",
      "Saved 300 segments for MDD S7  EC.set\n",
      "Processing MDD S9 EC.set...\n",
      "Saved 300 segments for MDD S9 EC.set\n",
      "Processing MDD S9 EO.set...\n",
      "Saved 300 segments for MDD S9 EO.set\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mne.io import read_raw_eeglab\n",
    "\n",
    "def process_set_files(input_folder):\n",
    "    # Create output directory\n",
    "    output_folder = \"Preprocessed_CSV\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all .set files\n",
    "    set_files = [f for f in os.listdir(input_folder) if f.endswith('.set')]\n",
    "    \n",
    "    for set_file in set_files:\n",
    "        print(f\"Processing {set_file}...\")\n",
    "        set_path = os.path.join(input_folder, set_file)\n",
    "        \n",
    "        try:\n",
    "            raw = read_raw_eeglab(set_path, preload=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {set_file}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Get EEG data (exclude non-EEG channels)\n",
    "        eeg_data = raw.get_data(picks='eeg')\n",
    "        sfreq = raw.info['sfreq']  # Sampling frequency (should be 256Hz)\n",
    "        n_channels, n_samples = eeg_data.shape\n",
    "        \n",
    "        # Calculate time points (0 to 1 second in steps of 1/sfreq)\n",
    "        time_column = np.arange(0, 1, 1/sfreq).reshape(-1, 1)  # Column vector\n",
    "        \n",
    "        # Segment into 1-second chunks\n",
    "        samples_per_segment = int(sfreq)\n",
    "        n_segments = n_samples // samples_per_segment\n",
    "        \n",
    "        # Get channel names for header\n",
    "        ch_names = raw.info['ch_names']\n",
    "        header = \"time,\" + \",\".join(ch_names)\n",
    "        \n",
    "        # Base filename without extension\n",
    "        base_name = os.path.splitext(set_file)[0]\n",
    "        \n",
    "        for seg_num in range(n_segments):\n",
    "            start = seg_num * samples_per_segment\n",
    "            end = start + samples_per_segment\n",
    "            segment = eeg_data[:, start:end].T  # Transpose to (time, channels)\n",
    "            \n",
    "            # Combine time column with EEG data\n",
    "            segment_with_time = np.hstack((time_column, segment))\n",
    "            \n",
    "            # Save as CSV\n",
    "            csv_name = f\"{base_name}_seg_{seg_num + 1}.csv\"\n",
    "            csv_path = os.path.join(output_folder, csv_name)\n",
    "            \n",
    "            np.savetxt(\n",
    "                csv_path,\n",
    "                segment_with_time,\n",
    "                delimiter=',',\n",
    "                header=header,\n",
    "                comments='',\n",
    "                fmt='%.6f'  # 6 decimal places for time and EEG values\n",
    "            )\n",
    "        \n",
    "        print(f\"Saved {n_segments} segments for {set_file}\")\n",
    "    \n",
    "    print(\"All files processed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"C:\\Users\\umaim\\Downloads\\preprocessed_data\"\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Error: Folder not found - {input_folder}\")\n",
    "    else:\n",
    "        process_set_files(input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abfc34-80e2-465a-b70a-b2790c9b96bb",
   "metadata": {},
   "source": [
    "## EEG Data Preprocessing\n",
    "EEG data was downloaded from an open source database (https://figshare.com/articles/dataset/EEG_Data_New/4244171) and preprocessed using EEGLAB on MATLAB. Preprocessing steps included: \n",
    "1. A band-pass filter (0.1-70 Hz) and a notch filter (50 Hz) were applied.\n",
    "2. Artifact subspace reconstruction (ASR)- an automated artifact rejection method\n",
    "3. Independent component analysis (ICA) is performed to remove artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b855321-b345-4242-823f-6ccc17f056d0",
   "metadata": {},
   "source": [
    "## Granger Causality Estimation\n",
    "\n",
    "Use Multivariate Granger Causality (MVGC) toolbox for GC estimation. The algorithm computes MVGC using time series data in both frequency and time domains. The current code processes 19 by 19 matrices, but will be updated for 38 by 38 matrices using frequency band decomposition for final presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ccee69-ad9a-4b14-acea-1ebb8b5124cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "def grangers_causation_matrix(data, variables, maxlag=4):\n",
    "    \"\"\"Generate Granger causality matrix with minimum p-values\"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), \n",
    "                     columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0]['ssr_chi2test'][1], 4) for i in range(maxlag)]\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    return df\n",
    "\n",
    "def process_eeg_files(input_folder, output_folder, maxlag=4):\n",
    "    \"\"\"Process all EEG files and save GC matrices with class labels\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Dictionary to store file paths by class\n",
    "    class_files = {'MDD': [], 'H': []}\n",
    "    \n",
    "    for filepath in glob.glob(os.path.join(input_folder, '*.csv')):\n",
    "        try:\n",
    "            filename = os.path.basename(filepath)\n",
    "            \n",
    "            # Determine class from filename (adjust this based on your naming convention)\n",
    "            if 'MDD' in filename or 'mdd' in filename.lower():\n",
    "                class_label = 'MDD'\n",
    "            else:\n",
    "                class_label = 'H'\n",
    "            \n",
    "            # Load and process data\n",
    "            data = pd.read_csv(filepath, index_col='time')\n",
    "            if len(data.columns) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Generate GC matrix\n",
    "            gc_matrix = grangers_causation_matrix(data, data.columns, maxlag)\n",
    "            \n",
    "            # Save with class label in filename\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            output_path = os.path.join(output_folder, f\"{class_label}_{base_name}_GCmatrix.npy\")\n",
    "            np.save(output_path, gc_matrix.values)\n",
    "            \n",
    "            class_files[class_label].append(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {str(e)}\")\n",
    "    \n",
    "    # Save the file list for each class\n",
    "    for class_label, files in class_files.items():\n",
    "        with open(os.path.join(output_folder, f'{class_label}_files.txt'), 'w') as f:\n",
    "            f.write('\\n'.join(files))\n",
    "    \n",
    "    return class_files\n",
    "\n",
    "# Usage\n",
    "input_folder = 'Preprocessed_CSV'\n",
    "output_folder = 'GC_Matrices'\n",
    "class_files = process_eeg_files(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d4832-ddb0-4305-b608-dcbcce394b7a",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5def1-93a0-4818-9430-56fc18bbe8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "data_dir = \"GC_matrices\"\n",
    "file_list = os.listdir(data_dir)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for file in file_list:\n",
    "    if file.endswith('.npy'):\n",
    "        # Load the matrix\n",
    "        matrix = np.load(os.path.join(data_dir, file))\n",
    "        \n",
    "        # Check if the matrix is 38x38\n",
    "        if matrix.shape == (19, 19):\n",
    "            X.append(matrix)\n",
    "            \n",
    "            # Label: 0 for healthy (\"H\" in filename), 1 for depressed (\"MDD\")\n",
    "            if 'H' in file:\n",
    "                y.append(0)\n",
    "            elif 'MDD' in file:\n",
    "                y.append(1)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Healthy (H): {np.sum(y == 0)}\")\n",
    "print(f\"Depressed (MDD): {np.sum(y == 1)}\")\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y)\n",
    "plt.xticks([0, 1], ['Healthy', 'MDD'])\n",
    "plt.title('Class Distribution')\n",
    "plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot sample matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot a healthy sample\n",
    "healthy_idx = np.where(y == 0)[0][np.random.randint(1,15000)]\n",
    "\n",
    "sns.heatmap(X[healthy_idx], ax=axes[0], cmap='viridis')\n",
    "axes[0].set_title('Healthy Sample - GC Matrix')\n",
    "\n",
    "# Plot a depressed sample\n",
    "mdd_idx = np.where(y == 1)[0][np.random.randint(1,15000)]\n",
    "sns.heatmap(X[mdd_idx], ax=axes[1], cmap='viridis')\n",
    "axes[1].set_title('MDD Sample - GC Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Add channel dimension for CNN (38, 38, 1)\n",
    "X_train_cnn = X_train[..., np.newaxis]\n",
    "X_val_cnn = X_val[..., np.newaxis]\n",
    "X_test_cnn = X_test[..., np.newaxis]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
