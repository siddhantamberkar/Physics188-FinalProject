
% Packages & Document Configurations
\documentclass[twocolumn]{NobArticle}
\runninghead{Shortened Running Article Title}
\footertext{\textit{Journal X} (2023) 12:684}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{graphicx}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
}
% Title
\title{Convolutional neural network classification of MDD with resting-state EEG}

% Authors
\author{
    Umaima Afifa, Jerry Chen, Emma Yu, Siddhant Amberkar, Jack Collard, and Ryu Kakuta
}


% Affiliations
\date{
    2025 December \_. University of California, Berkeley
}

% Abstract
\renewcommand{\maketitlehookd}{%
\begin{abstract}
    dsdf.

\end{abstract}
}

\begin{document}

\small
\maketitle

% Introduction
\section{Introduction}
    In 2023, 21 million Americans were found to have experienced a major depressive episode (\cite{BrodyHughes2025}). Major Depressive Disorder (MDD), commonly referred to as clinical depression, can be detected through electroencephalogram (EEG) analysis, allowing for early diagnosis and treatment. With the advancement of deep learning methods, specifically convolutional neural networks (CNN), medical diagnoses, from tumor classification to x-ray analysis, can be automated. Neural-network-based medical diagnoses significantly reduce the associated costs of traditional diagnostic methods, potentially allowing more patients to receive the treatment they need to manage MDD. Similar studies utilized a suite of wavelet transforms of EEG data (\cite{Bagherzadeh2025_CCADD}) as well as effective connectivity between electrode channels (\cite{Miljevic2023_EEGconnectivity}) to achieve high accuracy and F1-scores in automated CNN-based MDD classification, demonstrating the merit of this approach. 
    
    In this paper, we examine the sufficiency of effective connectivity as a classifier for CNN-based MDD diagnosis. Recent analysis of brain connectivity shows that patients diagnosed with MDD exhibit abnormally low functional brain connectivity across various scalp locations (\cite{Fogelson2020_predictiveEEG_MDD}). The deviations from healthy patients suggest that bi-directional connectivity between EEG signal channels may be highly correlated with log-odds of MDD probability in patients. Functional connectivity, though standard, only measures how correlated two signals are, omitting the strength and direction of the causal relation between the signals. In \cite{Miljevic2023_EEGconnectivity}, the authors discuss the nuance of effective connectivity, which measures both magnitude and direction in connectivity between signals. To measure effective connectivity, the authors use Grainger Causality (GC), a statistical test that determines whether past values of one time series can predict future values of another. GC can be analyzed in both time and frequency domains, of which the aformentioned paper uses a frequency-based method known as Partial Directed Coherence (PDC). This produces an $n\times n\times B$ matrix for each patient, where $n$ is the number of electrode channels and $B$ is the number of frequency bins. The dataset provided for our paper as well as the one referred to above use 19 electrode channels, located at various positions on patients' scalps to measure EEG among different brain functional lobes. By dimensionality reduction, the authors demonstrate that the PDC matrices can be reduced down to $6\times6\times B$ matrices, which constitute the brain default mode network (DMN). 

    While the authors present promising findings with high accuracy, their dataset is limited to 15 healthy control (HC) patients and 15 MDD patients, a relatively small sample size. In this paper, we use an updated dataset including 34 HC and 30 MDD patients, a two-fold increase in sample size. We also utilize both frequency and time domain GC methods using a multivariate Grainger Causality (MVGC) estimated on a multivariate autoregressive model (MVAR). Combining the frequency and time-based method resulting matrices, our final Grainger Matrix has dimension $2n\times2n\times B$, or $38\times38\times B$. Expanding on the approach outlined in \cite{Miljevic2023_EEGconnectivity}, this paper aims to improve 3D CNN  performance and extrapolation to a larger dataset. 


\section{Methods}
The sections below outline the data acquisition, postprocessing, and mathematical and computational frameworks used to train a 3D CNN for MDD classification. 
\subsection{EEG Signal Data}
Each EEG time series is acquired over a 5-min long recording of the participants during eye-close (EC) and eye-open (EO) resting states. A 19-electrode EEG cap was placed over participants' scalps at FP1, FP2, F3, F4, C3, C4, P3, P4, O1, O2, F7, F8, T3, T4, T5, T6, FZ, CZ, and PZ. The data were recorded with a sampling rate of 256 Hz, and preprocessed with a bandpass filter (0.1â€“70 Hz) and a 50-Hz notch filter. The EEGLAB software on Python was used for the automatic removal of artifacts using artifact subspace reconstruction (ASR) and independent component analysis (ICA). 

\subsection{Partial Directed Coherence (PDC)}
Partial directed coherence is the frequency-based counterpart to the time-based multivariate autoregressive model (MVAR) fit on EEG time series data. In this paper, we combine both time and frequency based MVGC estiamtes, which include the original and Fourier-transformed MVAR coefficients. 

Let the set of $n$ simultaneously measured time series 
\begin{equation}
    Y(t) = [y_1(t), y_2(t),..., y_n(t)]^T
\end{equation}

be represented by an autogressive model of order \textit{p} given by: 
\begin{equation}
    Y(t) = \sum_{l=1}^{p}{\textbf{A}_l\textbf{Y}(t-l)}\space + \boldsymbol{\varepsilon}(t)
\end{equation}
where $\textbf{A}_l$ is the coefficient matrix at time lag $l$ and $\boldsymbol{\varepsilon}(t)$ is background multivariate Gaussian noise with zero mean. The MVAR coefficients $a_{uv}(l)$ represent the the effect of $y_v(t-l)$ on $y_u(t)$. Thus, $\textbf{A}_l$ is the matrix corresponding to the time-based MVGC estimate. The frequency-based Fourier transformation of matrix $\textbf{A}_l$, $\textbf{A}(f)$ then has coefficients $a_{uv}(f) = \sum_{l=1}^{p}{a_{uv}(l)e^{-i(\tfrac{2\pi}{p})lf}}$. Centering the matrix $\textbf{A}(f)$ by subtracting $\textbf{I}_n$, we get $\bar{\textbf{A}}(f)$. Finally, the PDC from electrode $u$ to $v$ denoted by $\pi_{uv}(f)$ is defined as
\begin{equation}
    \pi_{uv}(f) = \dfrac{\bar{a}_{uv}(f)}{\sqrt{\bar{a}_v^H(f)\bar{a}_u(f)}}
\end{equation}

\subsection{MLP Neural Network}

One of the classification approaches explored in this study was a fully connected multilayer perceptron (MLP) neural network. The MLP was trained on flattened versions of the MVGC connectivity matrices derived from EEG recordings. 

\subsubsection{Input Processing}

Prior to classification, the diagonal elements of each MVGC matrix were removed by subtracting the identity matrix, eliminating trivial self-connections that do not carry diagnostic information. Each matrix was then flattened into a 361-dimensional feature vector and used as input to the neural network.

The dataset was split into training and test sets by subject, ensuring that EEG samples from the same individual did not appear in both sets. For the MDD group, 7 subjects were randomly selected for the test set, and the remaining 27 subjects were used for training. Similarly, for the healthy control (HC) group, 6 subjects were assigned to the test set, with the remaining 24 subjects used for training. All MVGC matrices corresponding to a given subject were included entirely in either the training or test set. This patient-wise split prevents data leakage and provides a more realistic estimate of generalization performance. Training labels were binary, with 0 indicating healthy controls and 1 indicating MDD patients.

Models were trained for up to 200 epochs with a batch size of 32. During training, both the loss and training accuracy were recorded at each epoch. Final model weights were selected based on the lowest observed training loss. 

\subsubsection{Network Architecture}

Figure~\ref{fig:mlp_architecture} shows the architecture of the multilayer perceptron (MLP) used for MDD classification. The model is implemented in PyTorch and consists of a sequence of fully connected layers that operate on flattened MVGC connectivity features. 

The network comprises multiple hidden layers with increasing and then decreasing dimensionality. ReLU activation functions are used in the early hidden layers, while the final hidden layer employs the Swish (SiLU) activation, which was found to improve convergence behavior and test accuracy. The output layer consists of a single unit with a sigmoid activation, producing the predicted probability of an MDD diagnosis.

To mitigate overfitting, dropout with a rate of 0.2 is applied to all hidden layers, and batch normalization is used to stabilize training. Model parameters are optimized using the Adam optimizer with a binary cross-entropy loss function. Early stopping based on training loss is employed during training; however, a notable gap between training and test accuracy remains, indicating limited generalization.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/MLP_arch}
    \caption{Architecture of the multilayer perceptron used for MDD classification. The network takes a flattened 361-dimensional MVGC feature vector as input and consists of multiple fully connected hidden layers with ReLU and Swish activations, followed by a sigmoid output layer for binary classification.}
    \label{fig:mlp_architecture}
\end{figure}


\subsubsection{Results}
Overall, deeper architectures with larger hidden layers performed better than shallower networks. In particular, models with multiple hidden layers and higher capacity achieved improved test accuracy compared to simpler configurations. The combination of ReLU activations in early layers and Swish activation in the final hidden layer consistently outperformed architectures using a single activation type. Additionally, the inclusion of dropout and batch normalization improved generalization performance.

The best-performing model achieved a test accuracy of approximately $61.2\%$, indicating modest but above-chance classification of MDD versus healthy controls based solely on MVGC connectivity features. Despite near-perfect training accuracy, test performance remained limited, suggesting overfitting and highlighting the difficulty of the classification task.

Figures~\ref{fig:mlp_loss} and~\ref{fig:mlp_accuracy} show the training loss and training accuracy curves, respectively, for this highest-performing MLP model. These plots illustrate the convergence behavior over epochs, the effect of early stopping, and the large gap between training and test performance, highlighting potential overfitting.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/MLP_loss.jpg}
    \caption{Training loss curve for the highest-performing MLP model (hidden layers 100, 500, 200, 50 with ReLU/Swish activations, dropout 0.2, and batch normalization). Loss decreases steadily until early stopping is triggered.}
    \label{fig:mlp_loss}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/MLP_accuracy.jpg}
    \caption{Training accuracy curve for the highest-performing MLP model. Accuracy approaches near-perfect values on the training set, highlighting a substantial gap relative to test accuracy and indicating overfitting.}
    \label{fig:mlp_accuracy}
\end{figure}

To better understand the behavior of the classifier beyond aggregate performance metrics, we performed a qualitative misclassification analysis on the test set. Figure~\ref{fig:mlp_confusion_examples} shows representative examples of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN), reconstructed from the flattened MVGC feature vectors back into their original $19 \times 19$ matrix form. Each row corresponds to a different test subject, allowing for direct visual comparison across classification outcomes.

These examples highlight systematic differences in connectivity structure between correctly and incorrectly classified samples. In particular, false negatives often exhibit connectivity patterns that visually resemble healthy controls, while false positives show increased or atypical connectivity that may overlap with MDD-associated features. This qualitative inspection suggests that the classifier is sensitive to subtle variations in functional connectivity, but struggles with cases where diagnostic patterns are weak or ambiguous.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/MLP_sample.png}
    \caption{Representative examples of MVGC connectivity matrices from the test set, grouped by classification outcome: true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN).}
    \label{fig:mlp_confusion_examples}
\end{figure}

\begin{table}[h]
\centering
\caption{Summary of MLP architectures and classification performance. All models use ReLU activations in early hidden layers, Swish activation in the final hidden layer, dropout of 0.2, and batch normalization.}
\begin{tabular}{l c c}
\hline
\textbf{Hidden Layer Sizes} & \textbf{Dropout} & \textbf{Test Accuracy (\%)} \\
\hline
100, 50, 20, 20 & 0.2 & 59.9 \\
100, 500, 200, 50 & 0.2 & \textbf{61.2} \\
100, 500, 200, 200, 50 & 0.2 & 60.8 \\
\hline
\end{tabular}
\end{table}

These results suggest that increased architectural complexity improves performance up to a point, beyond which additional layers yield diminishing returns. While the achieved accuracy remains limited, the findings demonstrate that EEG-derived Granger causality connectivity patterns contain diagnostically relevant information for MDD classification.


\subsection{3D Convolutional Neural Network M}

\subsection{Model Evaluation}

\subsection{Performance Evaluation}

\section{Results and Discussion}


\section{Conclusion}




\printbibliography

\end{document}
