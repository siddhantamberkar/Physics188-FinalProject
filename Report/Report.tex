
% Packages & Document Configurations
\documentclass[twocolumn]{NobArticle}
\runninghead{Shortened Running Article Title}
\footertext{\textit{Journal X} (2023) 12:684}
\usepackage{dsfont}
\usepackage{amsmath}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
}
% Title
\title{Convolutional neural network classification of MDD with resting-state EEG}

% Authors
\author{
    Umaima Afifa, Jerry Chen, Emma Yu, Siddhant Amberkar, Jack Collard, and Ryu Kakuta
}


% Affiliations
\date{
    2025 December \_. University of California, Berkeley
}

% Abstract
\renewcommand{\maketitlehookd}{%
\begin{abstract}
    dsdf.

\end{abstract}
}

\begin{document}

\small
\maketitle

% Introduction
\section{Introduction}
    In 2023, 21 million Americans were found to have experienced a major depressive episode (\cite{BrodyHughes2025}). Major Depressive Disorder (MDD), commonly referred to as clinical depression, can be detected through electroencephalogram (EEG) analysis, allowing for early diagnosis and treatment. With the advancement of deep learning methods, specifically convolutional neural networks (CNN), medical diagnoses, from tumor classification to x-ray analysis, can be automated. Neural-network-based medical diagnoses significantly reduce the associated costs of traditional diagnostic methods, potentially allowing more patients to receive the treatment they need to manage MDD. Similar studies utilized a suite of wavelet transforms of EEG data (\cite{Bagherzadeh2025_CCADD}) as well as effective connectivity between electrode channels (\cite{Miljevic2023_EEGconnectivity}) to achieve high accuracy and F1-scores in automated CNN-based MDD classification, demonstrating the merit of this approach. 
    
    In this paper, we examine the sufficiency of effective connectivity as a classifier for CNN-based MDD diagnosis. Recent analysis of brain connectivity shows that patients diagnosed with MDD exhibit abnormally low functional brain connectivity across various scalp locations (\cite{Fogelson2020_predictiveEEG_MDD}). The deviations from healthy patients suggest that bi-directional connectivity between EEG signal channels may be highly correlated with log-odds of MDD probability in patients. Functional connectivity, though standard, only measures how correlated two signals are, omitting the strength and direction of the causal relation between the signals. In \cite{Miljevic2023_EEGconnectivity}, the authors discuss the nuance of effective connectivity, which measures both magnitude and direction in connectivity between signals. To measure effective connectivity, the authors use Grainger Causality (GC), a statistical test that determines whether past values of one time series can predict future values of another. GC can be analyzed in both time and frequency domains, of which the aformentioned paper uses a frequency-based method known as Partial Directed Coherence (PDC). This produces an $n\times n\times B$ matrix for each patient, where $n$ is the number of electrode channels and $B$ is the number of frequency bins. The dataset provided for our paper as well as the one referred to above use 19 electrode channels, located at various positions on patients' scalps to measure EEG among different brain functional lobes. By dimensionality reduction, the authors demonstrate that the PDC matrices can be reduced down to $6\times6\times B$ matrices, which constitute the brain default mode network (DMN). 

    While the authors present promising findings with high accuracy, their dataset is limited to 15 healthy control (HC) patients and 15 MDD patients, a relatively small sample size. In this paper, we use an updated dataset including 34 HC and 30 MDD patients, a two-fold increase in sample size. We also utilize both frequency and time domain GC methods using a multivariate Grainger Causality (MVGC) estimated on a multivariate autoregressive model (MVAR). Combining the frequency and time-based method resulting matrices, our final Grainger Matrix has dimension $2n\times2n\times B$, or $38\times38\times B$. Expanding on the approach outlined in \cite{Miljevic2023_EEGconnectivity}, this paper aims to improve 3D CNN  performance and extrapolation to a larger dataset. 


\section{Methods}
The sections below outline the data acquisition, postprocessing, and mathematical and computational frameworks used to train a 3D CNN for MDD classification. 
\subsection{EEG Signal Data}
Each EEG time series is acquired over a 5-min long recording of the participants during eye-close (EC) and eye-open (EO) resting states. A 19-electrode EEG cap was placed over participants' scalps at FP1, FP2, F3, F4, C3, C4, P3, P4, O1, O2, F7, F8, T3, T4, T5, T6, FZ, CZ, and PZ. The data were recorded with a sampling rate of 256 Hz, and preprocessed with a bandpass filter (0.1–70 Hz) and a 50-Hz notch filter. The EEGLAB software on Matlab was used for the automatic removal of artifacts using artifact subspace reconstruction (ASR) and independent component analysis (ICA). 

\subsection{Partial Directed Coherence (PDC)}
Partial directed coherence is the frequency-based counterpart to the time-based multivariate autoregressive model (MVAR) fit on EEG time series data. In this paper, we combine both time and frequency based MVGC estiamtes, which include the original and Fourier-transformed MVAR coefficients. 

Let the set of $n$ simultaneously measured time series 
\begin{equation}
    Y(t) = [y_1(t), y_2(t),..., y_n(t)]^T
\end{equation}

be represented by an autogressive model of order \textit{p} given by: 
\begin{equation}
    Y(t) = \sum_{l=1}^{p}{\textbf{A}_l\textbf{Y}(t-l)}\space + \boldsymbol{\varepsilon}(t)
\end{equation}
where $\textbf{A}_l$ is the coefficient matrix at time lag $l$ and $\boldsymbol{\varepsilon}(t)$ is background multivariate Gaussian noise with zero mean. The MVAR coefficients $a_{uv}(l)$ represent the the effect of $y_v(t-l)$ on $y_u(t)$. Thus, $\textbf{A}_l$ is the matrix corresponding to the time-based MVGC estimate. The frequency-based Fourier transformation of matrix $\textbf{A}_l$, $\textbf{A}(f)$ then has coefficients $a_{uv}(f) = \sum_{l=1}^{p}{a_{uv}(l)e^{-i(\tfrac{2\pi}{p})lf}}$. Centering the matrix $\textbf{A}(f)$ by subtracting $\textbf{I}_n$, we get $\bar{\textbf{A}}(f)$. Finally, the PDC from electrode $u$ to $v$ denoted by $\pi_{uv}(f)$ is defined as
\begin{equation}
    \pi_{uv}(f) = \dfrac{\bar{a}_{uv}(f)}{\sqrt{\bar{a}_v^H(f)\bar{a}_u(f)}}
\end{equation}

\subsection{Granger Causality (GC) Estimation}

EEG data is highly suited for GC analysis due to its high temporal resolution, quick sampling, and often stochastic character (\cite{}). In this work, we use the Multivariate Granger Causality (MVGC) \cite{24} toolbox for GC estimation. The algorithm computes MVGC using time–series data in both the frequency and time domains. It eliminates separate full and reduced regressions, which are a typical cause of statistical inaccuracy and computational inefficiency, therefore improving upon traditional techniques for GC inference \cite{24}. 

The GC formalism relies on vector autoregressive (VAR) modeling for forecasting. VAR$(p)$ is calculated as follows:

\begin{equation}
    U_t = \sum_{k=1}^{p} A_k U_{t-k} + \varepsilon_t
\end{equation}

where $p$ is the model order. In this experiment, the Akaike Information Criterion (AIC) was used to establish the proper model order, helping to avoid under–representation or overfitting of the model \cite{48,49}. The AIC for $n$ variables is defined as

\begin{equation}
    \mathrm{AIC}(p) = \ln\big( \det(\Sigma) \big) + \frac{2pn^2}{T}
\end{equation}

where $\Sigma$ represents the prediction–error covariance matrix of the bivariate autoregressive model, $p$ is the model order, and $T$ is the signal length.

To demonstrate the conditional situation, the universe $U$, containing the known variables, is considered to be divided into three interdependent multivariate processes:

\begin{equation}
    U_t = \{ X_t,\; Y_t,\; Z_t \}
\end{equation}

and any combined influence of $Z$ on the determination of $Y$ to $X$ Granger–causality needs to be eliminated. The VAR$(p)$ model is analogously split into full and reduced regressions as follows:

\begin{equation}
    X_t = \sum_{k=1}^{p} A_{xx,k}X_{t-k} + \sum_{k=1}^{p} A_{xy,k}Y_{t-k} + \sum_{k=1}^{p} A_{xz,k}Z_{t-k} + \varepsilon_{x,t}
\end{equation}

\begin{equation}
    X_t = \sum_{k=1}^{p} A'_{xx,k} X_{t-k} + \sum_{k=1}^{p} A'_{xz,k} Z_{t-k} + \varepsilon'_{x,t}
\end{equation}

The causality $Y \rightarrow X$ conditioned on $Z$, written $F_{Y \rightarrow X|Z}$, is given by

\begin{equation}
    F_{Y \rightarrow X|Z} \equiv \ln \frac{\lvert \Sigma'_{xx} \rvert}{\lvert \Sigma_{xx} \rvert}
\end{equation}

In this case, the addition of $Z$ in both regressions is considered as its combined influence. $F_{Y \rightarrow X|Z}$ is interpreted as the extent to which the previous values of $Y$ assist in predicting $X$, beyond the amount to which $X$ is predicted by its own history and by $Z$'s history (\cite{}).

\subsection{3D Convolutional Neural Network M}

\subsection{Model Evaluation}

\subsection{Performance Evaluation}

\section{Results and Discussion}


\section{Conclusion}




\printbibliography

\end{document}
